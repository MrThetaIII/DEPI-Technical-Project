{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPI Twitter Sentiment Analysis Project\n",
    "\n",
    "## Data Analysis (Tokens frequency for each sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>words</th>\n",
       "      <th>grams</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_words</th>\n",
       "      <th>cleaned_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>['switchfoot', 'http', '', 'twitpiccom2y1zl', ...</td>\n",
       "      <td>['switchfoot http', 'http ', ' twitpiccom2y1zl...</td>\n",
       "      <td>['switchfoot']</td>\n",
       "      <td>[]</td>\n",
       "      <td>a that s a bummer you shoulda got david carr o...</td>\n",
       "      <td>['bummer', 'shoulda', 'got', 'david', 'carr', ...</td>\n",
       "      <td>['bummer shoulda', 'shoulda got', 'got david',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>['is', 'upset', 'that', 'he', 'ca', 'nt', 'upd...</td>\n",
       "      <td>['is upset', 'upset that', 'that he', 'he ca',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>['upset', 'update', 'facebook', 'texting', 'mi...</td>\n",
       "      <td>['upset update', 'update facebook', 'facebook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>['Kenichan', 'I', 'dived', 'many', 'times', 'f...</td>\n",
       "      <td>['Kenichan I', 'I dived', 'dived many', 'many ...</td>\n",
       "      <td>['Kenichan']</td>\n",
       "      <td>[]</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>['dived', 'many', 'times', 'ball', 'managed', ...</td>\n",
       "      <td>['dived many', 'many times', 'times ball', 'ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>['my', 'whole', 'body', 'feels', 'itchy', 'and...</td>\n",
       "      <td>['my whole', 'whole body', 'body feels', 'feel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>['whole', 'body', 'feels', 'itchy', 'like', 'f...</td>\n",
       "      <td>['whole body', 'body feels', 'feels itchy', 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>['nationwideclass', 'no', '', 'it', 's', 'not'...</td>\n",
       "      <td>['nationwideclass no', 'no ', ' it', 'it s', '...</td>\n",
       "      <td>['nationwideclass']</td>\n",
       "      <td>[]</td>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>['behaving', 'mad', 'see']</td>\n",
       "      <td>['behaving mad', 'mad see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          ID                          Date     Query  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              User                                               Text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['switchfoot', 'http', '', 'twitpiccom2y1zl', ...   \n",
       "1  ['is', 'upset', 'that', 'he', 'ca', 'nt', 'upd...   \n",
       "2  ['Kenichan', 'I', 'dived', 'many', 'times', 'f...   \n",
       "3  ['my', 'whole', 'body', 'feels', 'itchy', 'and...   \n",
       "4  ['nationwideclass', 'no', '', 'it', 's', 'not'...   \n",
       "\n",
       "                                               grams             mentions  \\\n",
       "0  ['switchfoot http', 'http ', ' twitpiccom2y1zl...       ['switchfoot']   \n",
       "1  ['is upset', 'upset that', 'that he', 'he ca',...                   []   \n",
       "2  ['Kenichan I', 'I dived', 'dived many', 'many ...         ['Kenichan']   \n",
       "3  ['my whole', 'whole body', 'body feels', 'feel...                   []   \n",
       "4  ['nationwideclass no', 'no ', ' it', 'it s', '...  ['nationwideclass']   \n",
       "\n",
       "  hashtags                                       cleaned_text  \\\n",
       "0       []  a that s a bummer you shoulda got david carr o...   \n",
       "1       []  is upset that he can t update his facebook by ...   \n",
       "2       []  i dived many times for the ball managed to sav...   \n",
       "3       []     my whole body feels itchy and like its on fire   \n",
       "4       []  no it s not behaving at all i m mad why am i h...   \n",
       "\n",
       "                                       cleaned_words  \\\n",
       "0  ['bummer', 'shoulda', 'got', 'david', 'carr', ...   \n",
       "1  ['upset', 'update', 'facebook', 'texting', 'mi...   \n",
       "2  ['dived', 'many', 'times', 'ball', 'managed', ...   \n",
       "3  ['whole', 'body', 'feels', 'itchy', 'like', 'f...   \n",
       "4                         ['behaving', 'mad', 'see']   \n",
       "\n",
       "                                       cleaned_grams  \n",
       "0  ['bummer shoulda', 'shoulda got', 'got david',...  \n",
       "1  ['upset update', 'update facebook', 'facebook ...  \n",
       "2  ['dived many', 'many times', 'times ball', 'ba...  \n",
       "3  ['whole body', 'body feels', 'feels itchy', 'i...  \n",
       "4                        ['behaving mad', 'mad see']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Target    Token  Type\n",
      "0       0   bummer  Word\n",
      "0       0  shoulda  Word\n",
      "0       0      got  Word\n",
      "0       0    david  Word\n",
      "0       0     carr  Word\n",
      "Target   Token  Type  Overall Frequency  Freq Neg  Freq Pos\n",
      "0           aa  Word                240       156        84\n",
      "177        aaa  Word                157        97        60\n",
      "289       aaaa  Word                 81        47        34\n",
      "345      aaaaa  Word                 39        27        12\n",
      "381     aaaaaa  Word                 30        17        13\n",
      "âœ… Token frequencies saved to: ./token_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('./cleaned_data.csv', low_memory=False)\n",
    "\n",
    "# Function to convert string representations of lists back to lists\n",
    "def convert_to_list(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Convert 'cleaned_words' and 'cleaned_grams' columns from strings to lists\n",
    "df['cleaned_words'] = df['cleaned_words'].apply(convert_to_list)\n",
    "df['cleaned_grams'] = df['cleaned_grams'].apply(convert_to_list)\n",
    "\n",
    "# Now proceed with processing\n",
    "# Process 'cleaned_words' (Words)\n",
    "words_df = df[['Target', 'cleaned_words']].explode('cleaned_words')\n",
    "words_df = words_df.rename(columns={'cleaned_words': 'Token'})\n",
    "words_df['Type'] = 'Word'\n",
    "\n",
    "print(words_df.head())\n",
    "\n",
    "# Process 'cleaned_grams' (Bi-Grams)\n",
    "bigrams_df = df[['Target', 'cleaned_grams']].explode('cleaned_grams')\n",
    "bigrams_df = bigrams_df.rename(columns={'cleaned_grams': 'Token'})\n",
    "bigrams_df['Type'] = 'Bi-Gram'\n",
    "\n",
    "# Combine 'words_df' and 'bigrams_df' into a single DataFrame\n",
    "tokens_df = pd.concat([words_df, bigrams_df], ignore_index=True)\n",
    "\n",
    "# Ensure 'Token' column has string type for consistency\n",
    "tokens_df['Token'] = tokens_df['Token'].astype(str)\n",
    "\n",
    "# Proceed with the rest of the processing...\n",
    "\n",
    "# Step 2: Group by 'Token', 'Type', and 'Target' to calculate frequencies\n",
    "\n",
    "# Calculate frequency counts\n",
    "freq = (\n",
    "    tokens_df.groupby(['Token', 'Type', 'Target'])\n",
    "    .size()\n",
    "    .reset_index(name='Frequency')\n",
    ")\n",
    "\n",
    "# Step 3: Pivot the table to get frequencies for each sentiment\n",
    "\n",
    "# Pivot the DataFrame to have separate columns for negative and positive frequencies\n",
    "freq_pivot = freq.pivot_table(\n",
    "    index=['Token', 'Type'],\n",
    "    columns='Target',\n",
    "    values='Frequency',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "freq_pivot = freq_pivot.rename(columns={\n",
    "    0: 'Freq Neg',\n",
    "    4: 'Freq Pos'\n",
    "})\n",
    "\n",
    "# Ensure 'Freq Neg' and 'Freq Pos' columns exist even if there are no occurrences\n",
    "if 'Freq Neg' not in freq_pivot.columns:\n",
    "    freq_pivot['Freq Neg'] = 0\n",
    "if 'Freq Pos' not in freq_pivot.columns:\n",
    "    freq_pivot['Freq Pos'] = 0\n",
    "\n",
    "# Step 4: Calculate the Overall Frequency\n",
    "\n",
    "freq_pivot['Overall Frequency'] = freq_pivot['Freq Neg'] + freq_pivot['Freq Pos']\n",
    "\n",
    "# Reorder the columns\n",
    "final_df = freq_pivot[['Token', 'Type', 'Overall Frequency', 'Freq Neg', 'Freq Pos']]\n",
    "\n",
    "# Remove Tokens with 1 overall frequency\n",
    "final_df = final_df[final_df['Overall Frequency'] > 10]\n",
    "\n",
    "# Remove 'nan' Bi-Gram Token\n",
    "final_df = final_df[final_df['Token'] != 'nan']\n",
    "\n",
    "# Step 5: Display or Save the Result\n",
    "\n",
    "print(final_df.head())\n",
    "\n",
    "# Optionally, save the final DataFrame to a CSV file\n",
    "output_path = \"./token_frequencies.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(\"âœ… Token frequencies saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>Token</th>\n",
       "      <th>Type</th>\n",
       "      <th>Overall Frequency</th>\n",
       "      <th>Freq Neg</th>\n",
       "      <th>Freq Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980707</th>\n",
       "      <td>last night</td>\n",
       "      <td>Bi-Gram</td>\n",
       "      <td>12524</td>\n",
       "      <td>7556</td>\n",
       "      <td>4968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461242</th>\n",
       "      <td>good morning</td>\n",
       "      <td>Bi-Gram</td>\n",
       "      <td>10168</td>\n",
       "      <td>1943</td>\n",
       "      <td>8225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085130</th>\n",
       "      <td>wish could</td>\n",
       "      <td>Bi-Gram</td>\n",
       "      <td>6816</td>\n",
       "      <td>5782</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192504</th>\n",
       "      <td>feel like</td>\n",
       "      <td>Bi-Gram</td>\n",
       "      <td>6559</td>\n",
       "      <td>5129</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117269</th>\n",
       "      <td>looking forward</td>\n",
       "      <td>Bi-Gram</td>\n",
       "      <td>5624</td>\n",
       "      <td>2195</td>\n",
       "      <td>3429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target             Token     Type  Overall Frequency  Freq Neg  Freq Pos\n",
       "1980707       last night  Bi-Gram              12524      7556      4968\n",
       "1461242     good morning  Bi-Gram              10168      1943      8225\n",
       "4085130       wish could  Bi-Gram               6816      5782      1034\n",
       "1192504        feel like  Bi-Gram               6559      5129      1430\n",
       "2117269  looking forward  Bi-Gram               5624      2195      3429"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['Type']=='Bi-Gram'].sort_values(by='Overall Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>Token</th>\n",
       "      <th>Type</th>\n",
       "      <th>Overall Frequency</th>\n",
       "      <th>Freq Neg</th>\n",
       "      <th>Freq Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1457262</th>\n",
       "      <td>good</td>\n",
       "      <td>Word</td>\n",
       "      <td>91324</td>\n",
       "      <td>29207</td>\n",
       "      <td>62117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840831</th>\n",
       "      <td>day</td>\n",
       "      <td>Word</td>\n",
       "      <td>89556</td>\n",
       "      <td>41373</td>\n",
       "      <td>48183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378972</th>\n",
       "      <td>get</td>\n",
       "      <td>Word</td>\n",
       "      <td>82172</td>\n",
       "      <td>45610</td>\n",
       "      <td>36562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041425</th>\n",
       "      <td>like</td>\n",
       "      <td>Word</td>\n",
       "      <td>78573</td>\n",
       "      <td>41053</td>\n",
       "      <td>37520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423636</th>\n",
       "      <td>go</td>\n",
       "      <td>Word</td>\n",
       "      <td>74006</td>\n",
       "      <td>45634</td>\n",
       "      <td>28372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target  Token  Type  Overall Frequency  Freq Neg  Freq Pos\n",
       "1457262  good  Word              91324     29207     62117\n",
       "840831    day  Word              89556     41373     48183\n",
       "1378972   get  Word              82172     45610     36562\n",
       "2041425  like  Word              78573     41053     37520\n",
       "1423636    go  Word              74006     45634     28372"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['Type']=='Word'].sort_values(by='Overall Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target          Token     Type  Overall Frequency  Freq Neg  Freq Pos\n",
      "1               0001t  Mention                  3         2         1\n",
      "2        000catnap000     User                  6         1         5\n",
      "6           0010x0010  Mention                  2         0         2\n",
      "8         001BabyGirl     User                  2         0         2\n",
      "15      007_Chris_007     User                  6         3         3\n",
      "âœ… Sentiment distribution for mentions, hashtags, URLs, and users saved to: ./entities_sentiment_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Assuming 'df' is the DataFrame we are working with\n",
    "\n",
    "# If not already done, read the CSV file into a DataFrame\n",
    "# df = pd.read_csv('./cleaned_data.csv', low_memory=False)\n",
    "\n",
    "# Function to convert string representations of lists back to lists\n",
    "def convert_to_list(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Convert 'mentions' and 'hashtags' columns from strings to lists\n",
    "df['mentions'] = df['mentions'].apply(convert_to_list)\n",
    "df['hashtags'] = df['hashtags'].apply(convert_to_list)\n",
    "\n",
    "# Ensure 'mentions' and 'hashtags' columns are lists\n",
    "df['mentions'] = df['mentions'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df['hashtags'] = df['hashtags'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# --- Process Mentions ---\n",
    "mentions_df = df[['Target', 'mentions']].explode('mentions')\n",
    "mentions_df = mentions_df.rename(columns={'mentions': 'Token'})\n",
    "mentions_df['Type'] = 'Mention'\n",
    "\n",
    "# Remove NaN tokens if any\n",
    "mentions_df = mentions_df[mentions_df['Token'].notna()]\n",
    "\n",
    "# --- Process Hashtags ---\n",
    "hashtags_df = df[['Target', 'hashtags']].explode('hashtags')\n",
    "hashtags_df = hashtags_df.rename(columns={'hashtags': 'Token'})\n",
    "hashtags_df['Type'] = 'Hashtag'\n",
    "\n",
    "# Remove NaN tokens if any\n",
    "hashtags_df = hashtags_df[hashtags_df['Token'].notna()]\n",
    "\n",
    "# --- Process URLs ---\n",
    "\n",
    "# Function to extract URLs from 'Text'\n",
    "def extract_urls(text):\n",
    "    url_pattern = re.compile(r'http[s]?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.findall(text)\n",
    "\n",
    "# Create a new column 'URLs' by extracting from 'Text'\n",
    "df['URLs'] = df['Text'].apply(extract_urls)\n",
    "\n",
    "# Process 'URLs'\n",
    "df['URLs'] = df['URLs'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "urls_df = df[['Target', 'URLs']].explode('URLs')\n",
    "urls_df = urls_df.rename(columns={'URLs': 'Token'})\n",
    "urls_df['Type'] = 'URL'\n",
    "\n",
    "# Remove NaN tokens if any\n",
    "urls_df = urls_df[urls_df['Token'].notna()]\n",
    "\n",
    "# --- Process Users ---\n",
    "\n",
    "# 'User' column contains usernames\n",
    "users_df = df[['Target', 'User']].rename(columns={'User': 'Token'})\n",
    "users_df['Type'] = 'User'\n",
    "\n",
    "# Remove NaN tokens if any\n",
    "users_df = users_df[users_df['Token'].notna()]\n",
    "\n",
    "# --- Combine All Entities ---\n",
    "\n",
    "entities_df = pd.concat([mentions_df, hashtags_df, urls_df, users_df], ignore_index=True)\n",
    "\n",
    "# Ensure 'Token' column has string type\n",
    "entities_df['Token'] = entities_df['Token'].astype(str)\n",
    "entities_df['Type'] = entities_df['Type'].astype(str)\n",
    "\n",
    "# Remove tokens that are empty strings\n",
    "entities_df = entities_df[entities_df['Token'].str.strip() != '']\n",
    "\n",
    "# --- Calculate Frequencies ---\n",
    "\n",
    "# Group by 'Token', 'Type', and 'Target' to calculate frequencies\n",
    "freq = (\n",
    "    entities_df.groupby(['Token', 'Type', 'Target'])\n",
    "    .size()\n",
    "    .reset_index(name='Frequency')\n",
    ")\n",
    "\n",
    "# Pivot the DataFrame to have separate columns for negative and positive frequencies\n",
    "freq_pivot = freq.pivot_table(\n",
    "    index=['Token', 'Type'],\n",
    "    columns='Target',\n",
    "    values='Frequency',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "freq_pivot = freq_pivot.rename(columns={\n",
    "    0: 'Freq Neg',\n",
    "    4: 'Freq Pos'\n",
    "})\n",
    "\n",
    "# Ensure 'Freq Neg' and 'Freq Pos' columns exist even if there are no occurrences\n",
    "if 'Freq Neg' not in freq_pivot.columns:\n",
    "    freq_pivot['Freq Neg'] = 0\n",
    "if 'Freq Pos' not in freq_pivot.columns:\n",
    "    freq_pivot['Freq Pos'] = 0\n",
    "\n",
    "# Calculate the Overall Frequency\n",
    "freq_pivot['Overall Frequency'] = freq_pivot['Freq Neg'] + freq_pivot['Freq Pos']\n",
    "\n",
    "# Reorder the columns\n",
    "final_entities_df = freq_pivot[['Token', 'Type', 'Overall Frequency', 'Freq Neg', 'Freq Pos']]\n",
    "\n",
    "# Remove Tokens with Overall Frequency <= 1 if desired\n",
    "final_entities_df = final_entities_df[final_entities_df['Overall Frequency'] > 1]\n",
    "\n",
    "# Remove 'nan' Tokens if any\n",
    "final_entities_df = final_entities_df[final_entities_df['Token'] != 'nan']\n",
    "\n",
    "# --- Display or Save the Result ---\n",
    "\n",
    "print(final_entities_df.head())\n",
    "\n",
    "# Optionally, save the final DataFrame to a CSV file\n",
    "output_path_entities = \"./entities_sentiment_distribution.csv\"\n",
    "final_entities_df.to_csv(output_path_entities, index=False)\n",
    "print(\"âœ… Sentiment distribution for mentions, hashtags, URLs, and users saved to:\", output_path_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>Token</th>\n",
       "      <th>Type</th>\n",
       "      <th>Overall Frequency</th>\n",
       "      <th>Freq Neg</th>\n",
       "      <th>Freq Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1076688</th>\n",
       "      <td>www.tweeteradder.com</td>\n",
       "      <td>URL</td>\n",
       "      <td>830</td>\n",
       "      <td>0</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651162</th>\n",
       "      <td>http://tweet.sg</td>\n",
       "      <td>URL</td>\n",
       "      <td>751</td>\n",
       "      <td>488</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076689</th>\n",
       "      <td>www.tweeterfollow.com</td>\n",
       "      <td>URL</td>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074207</th>\n",
       "      <td>www...</td>\n",
       "      <td>URL</td>\n",
       "      <td>331</td>\n",
       "      <td>196</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075304</th>\n",
       "      <td>www.iamsoannoyed.com</td>\n",
       "      <td>URL</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target                   Token Type  Overall Frequency  Freq Neg  Freq Pos\n",
       "1076688   www.tweeteradder.com  URL                830         0       830\n",
       "651162         http://tweet.sg  URL                751       488       263\n",
       "1076689  www.tweeterfollow.com  URL                654         0       654\n",
       "1074207                 www...  URL                331       196       135\n",
       "1075304   www.iamsoannoyed.com  URL                245         0       245"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_entities_df[final_entities_df['Type']=='URL'].sort_values(by='Overall Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>Token</th>\n",
       "      <th>Type</th>\n",
       "      <th>Overall Frequency</th>\n",
       "      <th>Freq Neg</th>\n",
       "      <th>Freq Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841265</th>\n",
       "      <td>mileycyrus</td>\n",
       "      <td>Mention</td>\n",
       "      <td>4500</td>\n",
       "      <td>1456</td>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038562</th>\n",
       "      <td>tommcfly</td>\n",
       "      <td>Mention</td>\n",
       "      <td>3887</td>\n",
       "      <td>1667</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517456</th>\n",
       "      <td>ddlovato</td>\n",
       "      <td>Mention</td>\n",
       "      <td>3467</td>\n",
       "      <td>1321</td>\n",
       "      <td>2146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85319</th>\n",
       "      <td>DavidArchie</td>\n",
       "      <td>Mention</td>\n",
       "      <td>1299</td>\n",
       "      <td>359</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164481</th>\n",
       "      <td>Jonasbrothers</td>\n",
       "      <td>Mention</td>\n",
       "      <td>1287</td>\n",
       "      <td>393</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target           Token     Type  Overall Frequency  Freq Neg  Freq Pos\n",
       "841265      mileycyrus  Mention               4500      1456      3044\n",
       "1038562       tommcfly  Mention               3887      1667      2220\n",
       "517456        ddlovato  Mention               3467      1321      2146\n",
       "85319      DavidArchie  Mention               1299       359       940\n",
       "164481   Jonasbrothers  Mention               1287       393       894"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_entities_df[final_entities_df['Type']=='Mention'].sort_values(by='Overall Frequency', ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
